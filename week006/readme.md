# WEEK 006
## Goal
1. 分類の問題をやってみる
1. 分類を行う際の予測結果を可視化してみる
1. パラメータをチューニングしてみる

## 1. 必要ライブラリのインストール
### 必要ライブラリ
 + scikits-learn
 + Graphviz: 可視化ツール

### インストール
    pip install scikits-learn
    brew install graphviz
    pip install graphviz
    pip install pydotplus

## [2. 分類をしてみる ](practice/classification.ipynb)
今回は銀行の仮想顧客属性データを使い、顧客キャンペーンに申し込みそうな人を予測してみるよ！<br>
ということで、以下が今回の予測のやることのざっくりまとめ。
 + 問題: 0 or 1の2値分類
 + モデル: 決定木モデル
 + 評価尺度: AUC

## 3. 少し解説
### ざっくり分類とは?
ある複数の状態 (今回はキャンペーンに申し込む or 申し込まない) のいずれかになる確率を予測するような問題。<br>
有名なものだと、DeepLearningの猫の画像と猫でない画像の2値分類など

### 決定木とは?
教師あり学習の手法の一つ。<br>
説明変数がどのような変遷をすることにより目的変数に達するかのifdefのルールを作成することで予測を行う手法。<br>
目的変数を根、説明変数を使用したルールを葉として表す、ツリー構造をとる。

例えば、ゴルフ場の来場状況から以下のような決定木が作れる。
そして、決定木で表されるif-defルールに従って予測を行う
![ゴルフ場来場状況](https://image.slidesharecdn.com/random-140616231740-phpapp01/95/-2-638.jpg?cb=1402967878)

### AUCとは?
ROC曲線を作成したときの、グラフの曲線より下の部分の面積を使用した評価。<br>
0 ~ 1までの値を取り、1に近いほど判別精度が高いことを示す。<br>
AUC は Area Under the Curveの略。<br>
AUC が 1に近いモデルとは、
 + 知りたい値(1)を正しく捕捉する(1)確率が高くかつ
 + 知りたくない値(0)を謝って捕捉する(1)確率が高い
モデルと言える。

### ROC曲線とは?
今回のような２値分類の場合、予測の結果は以下の4パターンになる。
 + 正解データ=Trueのものを、正しく予測
 + 正解データ=Falseのものを、正しく予測
 + 正解データ=Trueのものを、謝って予測
 + 正解データ=Falseのものを、謝って予測

表にすると以下.

| TrueをTrueと判定 <br> True Positive   | TrueをFalseと判定 <br> False Negative|
|---------------------------------------|--------------------------------------|
| FalseをTrueと判定 <br> False Positive | FalseをFalseと判定 <br> True Negative|

True Positiveなどは、
<予測に成功したか> - <予測した値>
を表している。(予測値がTrueの時をPositiveとしている)
なので、True Postive が多く、False Positiveが低いモデルを作りたい。

作ったモデルでテストデータを予測した場合の確度のスコアをプロットしたものがROC曲線。<br>
(Trueのデータのスコアが0.8なら、True Positice: 0.8, True False 0.2となる)
![ROC](https://oku.edu.mie-u.ac.jp/~okumura/stat/img/091007a.png)
縦軸はTrue Positive, 横軸は False Positive。

ROC はReceiver Operating Charactericticの略で、第二次大戦の時にレーダーの研究で生まれたらしい。

## [3. パラメータチューニング](practice/classification.ipynb)　
### パラメータとは？
データに合わせて、モデルを調整するための設定値。モデルが複雑になるほどパラメータ数が増える。
ハイパーパラメータとも言う。

#### 決定木で重要なパラメータ
 + max_depth
    + ツリーの構造が深いほど、事象の説明力が上がる
    + 構造が深くなるほど意味のない分岐が発生する可能性が上がるため、過学習が発生する恐れがある
 + min_samples_heaf
    + 葉に属するサンプル数の最小値
    + サンプル数が少ないと、一般的に信憑性が低くなる

#### パラメータの検証方法
 - パラメータは注意してチューニングしないと過学習してしまう危険あり
 - 未知のデータに対しても予測できるように調整しないといかん
   - 答えがわかっているデータ(学習データ)から仮の未知データを作ればいい。
   - 評価データで、パラメータの検証を行ってしまうと、未知データへのモデル評価ができない。(評価データも既知のデータとなってしまう)
   - よって、パラメータの評価とモデル全体の評価とでデータを分ける必要あり


データ分割
 - データセット
   - 学習データ
     - モデル構築データ
     - モデル検証データ
   - 評価データ


##### 実際にどのように良いパラメータを見つける？
1. 構築データでモデル を作成します
1. 構築データで予測を行い、精度検証
1. 検証データで予測を行い、精度検証
1. 構築データ, 検証データでの精度の乖離が少なく、検証データの精度が良いパラメータを選ぶ


                ここがベスト
    precision   |
    |           v     +  構築データ
    |             +
    |          +
    |       +
    |    +    -  -
    |  +   -        -
    | + -              -
    |+-
    +--------------------モデルの複雑さ


##### 最適化はどうやるの？
いろんなやり方があるが、今回はグリッドサーチを使用する。

###### グリッドサーチとは？
大仰な名前だが、パラメータの範囲を指定、その範囲をしらみつぶしに探索することをグリッドサーチと言う。<br>
グリッドサーチ + クロスバリデーション(後述)の組み合わせはよくパラメータ探索の方法として使われる。

##### 代表的な分割方法は?
1. ホールドアウト
   - 単純な方法
     - (通例7: 3)に構築データ, 検証データに分割する方法
     - どこで分割するかで精度が代わり不安定であるという欠点あり
   - データが大量にあれば有効
1. クロスバリデーション
   - K分割交差検証とも言われる (K-1...とも言ったりする。知ってた名前)
     - データをK個に分割し、検証をK回繰り返す。
     - K-1 個をモデル構築データとし、残り1個をモデル検証データ
     - 上記を全組合せで行い、K組の平均精度を元にパラメータを決定する
   - ホールドアウトの欠点を補った手法
   - 計算に時間がかかる



